{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/jlgrons/CELEHS-DSinA/blob/main/Week_2_Materials/EDA.ipynb","timestamp":1689169617278}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exploratory Data Analysis\n","\n","The MedMNIST dataset is licensed under Creative Commons Attribution 4.0 International (CC BY 4.0). The dataset is from the following paper:\n","\n","* Jiancheng Yang, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, Bingbing Ni. \"MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification\". arXiv preprint arXiv:2110.14795, 2021.\n","* Jiancheng Yang, Rui Shi, Bingbing Ni. \"MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis\". IEEE 18th International Symposium on Biomedical Imaging (ISBI), 2021.\n","\n","The MedMNIST dataset contains medical imaging data ranging from colonoscopy imaging to abdominal CT scans to breast ultrasounds.  There two main types of data formats that are used: 2 dimensional images and 3 dimensional.\n"],"metadata":{"id":"Xw4fpQLtcNex"}},{"cell_type":"markdown","source":["----\n","## Install required packages and datset\n","\n","**Goal:** Install the necessary packages and dataset\n","\n","*Note that this will take a few minutes to run...*"],"metadata":{"id":"6G6y4tHMIxjz"}},{"cell_type":"code","source":["# Terminal command for installing packages. pip is commonly used to install any python package.  Here, we pass in medmnist as the package name.  You can install any existing python packages using the command format pip install XXX, where XXX is the name of the desired package.\n","! pip install medmnist\n","! pip install keras\n","\n","# Import medmnist dataset\n","import medmnist\n","from medmnist import INFO, Evaluator\n","\n","# Import keras and tensorflow\n","import torchvision.transforms as transforms\n","\n","# Import utlity packages\n","import numpy as np\n","import random"],"metadata":{"id":"QzhLkheFIXnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","## Load in the dataset\n","\n","**Goal:** After installing the dataset (in the step above), we need to now load in the dataset so that we can use the dataset in our code.\n","\n","*Note that there are multiple steps for this process...*"],"metadata":{"id":"PhigVqYZLRo8"}},{"cell_type":"markdown","source":["### Step 1: Load helper functions\n","\n","There are a few functions that can help us load in the dataset. Run the cell below to load up the helper functions we need.\n","\n","You don't need to worry about understanding the functions get_loader and shuffle_iterator (those are for simply loading in the data from MedMNIST).  If you want to learn more about the dataset itself as well as the code and paper you can visit the MedMNIST website at https://medmnist.com/."],"metadata":{"id":"EExSfLZIeqzr"}},{"cell_type":"code","source":["# Helper function for retrieving the dataset\n","def get_loader(dataset, batch_size):\n","    total_size = len(dataset)\n","    print('Size', total_size)\n","    index_generator = shuffle_iterator(range(total_size))\n","    while True:\n","        data = []\n","        for _ in range(batch_size):\n","            idx = next(index_generator)\n","            data.append(dataset[idx])\n","        yield dataset._collate_fn(data)\n","\n","# This function takes in an iterator and shuffles the order of the items in it\n","def shuffle_iterator(iterator):\n","    # iterator should have limited size\n","    index = list(iterator)\n","    total_size = len(index)\n","    i = 0\n","    random.shuffle(index)\n","    while True:\n","        yield index[i]\n","        i += 1\n","        if i >= total_size:\n","            i = 0\n","            random.shuffle(index)\n","\n","# This transforms our data through tensor building and normalization.\n","data_transform = transforms.Compose([\n","                                     transforms.ToTensor(),\n","                                     transforms.Normalize(mean=[.5], std=[.5])\n","                                    ])"],"metadata":{"id":"49348C-fLUqs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2: Specify dataset\n","\n","There are many different possible datasets that we can use, so we need to specify the dataset we want to use (and other parameters needed to run a model on that dataset)."],"metadata":{"id":"Z0fUcR0efecH"}},{"cell_type":"code","source":["data_flag = 'pathmnist'\n","download = True\n","\n","NUM_EPOCHS = 3\n","BATCH_SIZE = 64\n","\n","info = INFO[data_flag]\n","task = info['task']\n","n_channels = info['n_channels']\n","n_classes = len(info['label'])\n","\n","DataClass = getattr(medmnist, info['python_class'])"],"metadata":{"id":"jXeEto3ndASH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 3: Load the data\n","\n","Now that we have set up the parameters required to load the dataset we want, let's finally load the data. Run the next cell to load the dataset that we will use to train and test our model. *Note that this will take a few minutes...*"],"metadata":{"id":"6Z7V1flwfyLF"}},{"cell_type":"code","source":["train_dataset = DataClass(split='train', transform=data_transform, download=download)\n","test_dataset = DataClass(split='test', transform=data_transform, download=download)"],"metadata":{"id":"SUW3qahTdTgy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 4: Split the data\n","\n","After loading in the data, we need to process it a little bit. We want to (1) create a loader for running our model and (2) extract the images and labels that are in the train/test datasets."],"metadata":{"id":"n2DxgvOYgdtj"}},{"cell_type":"code","source":["# (1) Create loaders for running our model\n","train_loader = get_loader(dataset=train_dataset, batch_size=BATCH_SIZE)\n","test_loader = get_loader(dataset=test_dataset, batch_size=BATCH_SIZE)\n","\n","# (2) Split the dataset into images and labels using numpy and list comprehensions\n","training_images = np.array([np.array(elem[0]) for elem in train_dataset])\n","training_labels = np.array([np.array(elem[1]) for elem in train_dataset])\n","testing_images = np.array([np.array(elem[0]) for elem in test_dataset])\n","testing_labels = np.array([np.array(elem[1]) for elem in test_dataset])"],"metadata":{"id":"6o9tO_PSgVIj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above code separates the datasets into the respective images and labels. We will look into the images and labels in more detail."],"metadata":{"id":"TOQeuXK9hcFu"}},{"cell_type":"markdown","source":["----\n","## Analyze our data\n","\n","**Goal:** Now that we've loaded our data, let's explore it and see what insights it holds."],"metadata":{"id":"gVYmbGZbhYBw"}},{"cell_type":"markdown","source":["### Step 1: Summarize data"],"metadata":{"id":"F5_oJlgQkjSE"}},{"cell_type":"code","source":["print(train_dataset)"],"metadata":{"id":"kJpgHahVhjiX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Try it yourself!** Get a summary of the testing dataset"],"metadata":{"id":"O6yC-NWThGef"}},{"cell_type":"code","source":[],"metadata":{"id":"VD63fDmAnA9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Try it yourself!** Explore the data to answer the following questions"],"metadata":{"id":"1ClGJ6W_lgfb"}},{"cell_type":"markdown","source":["*Question #1:* How many datapoints are in the train dataset?\n","\n","*Answer:* Write your answer here (double click on cell to type)"],"metadata":{"id":"kOhsCxoHln_c"}},{"cell_type":"markdown","source":["*Question #2:* How many datapoints are in the test dataset?\n","\n","*Answer:* Write your answer here (double click on cell to type)"],"metadata":{"id":"-7hxVvrbl1qA"}},{"cell_type":"markdown","source":["*Question #3:* How many labels are in the dataset?\n","\n","*Answer:* Write your answer here (double click on cell to type)"],"metadata":{"id":"KMCdlD0LmNRS"}},{"cell_type":"markdown","source":["### Step 2: Examine individual data points (images)\n","\n","Let's now take a look at individual pictures.  We can look at the images with and without colors."],"metadata":{"id":"Xt-SX1B7lI5U"}},{"cell_type":"markdown","source":["**Examine multiple images at a time:** You can edit the parameter length to display however many images you want.  For example, if you wanted to see five images you can change it to `train_dataset.montage(length=5)`."],"metadata":{"id":"LC0z1m5Cnort"}},{"cell_type":"code","source":["\"\"\"\n","The .montage() function takes in a parameter called length, which allows you to\n","set the number of images per row and per column to output in a square montage.\n","\n","This function is specific to the DataClass class. In this example, we have set\n","the parameter length to 20, and we can count 20 images as the side length of\n","the square montage.\n","\"\"\"\n","\n","train_dataset.montage(length=20)"],"metadata":{"id":"Yral-OPEnbu6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Examine one image at a time:** You can use `i` to select the image that you want to see. `i` represents the index of the image in the dataset. This means if `i` is 3, then the image displayed will be the 3rd image in the dataset."],"metadata":{"id":"k0WuuUt5o3-V"}},{"cell_type":"code","source":["# Import visualization package\n","from matplotlib import pyplot as plt"],"metadata":{"id":"kmzDoO9oohrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize the image at index i (grayscale)\n","\n","i = 300\n","\n","print(\"Label: \" + str(training_labels[i]))\n","\n","# imshow can take in an image in array format\n","plt.imshow(training_images[i][1])\n","plt.show()"],"metadata":{"id":"A8vHbzrfooHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a single image and putting it in a 3D array format for viewing\n","\n","single_image = []\n","for j in range(28):\n","  tmp = []\n","  for k in range(28):\n","    tmp.append((training_images[i][0][j][k], training_images[i][1][j][k], training_images[i][2][j][k]))\n","  single_image.append(tmp)\n","\n","# Plotting\n","plt.imshow(single_image)\n","plt.show()"],"metadata":{"id":"dZZocnNRFSf6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Examine labels of images:** Now, let's look at what the images are of. We can (1) summarize the dataset to see what the labels mean, (2) print out the labels in our training set, and (3) calculate how many of each label is in our training set."],"metadata":{"id":"OW7WSw3SpPTm"}},{"cell_type":"code","source":["# Print out the summary of the dataset\n","print(train_dataset)"],"metadata":{"id":"PlIOY-Air5ga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# View the labels in number format\n","labels = [item[0] for item in training_labels]\n","print(\"Labels of train dataset:\")\n","print(labels)"],"metadata":{"id":"SXPnHBISqY42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How many \"adipose\" are in the training labels?\n","# Hint: The number that represents \"adipose\" is 0.\n","print(\"Number of images of 'adipose' in the train dataset:\", labels.count(0))"],"metadata":{"id":"VYS-Z8RXrn4z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Try it yourself!** Create a dictionary called `number_classes` to map each label to the number of times it appears in the training dataset.\n","\n","An example of a label is \"adipose\". We calculated how many times it appears in the training labels. Now, let's repeat that for all of the labels and save it to the `number_classes` dictionary."],"metadata":{"id":"3Qp2qVgPsWPh"}},{"cell_type":"code","source":["number_classes = {} # Fill in the blank\n","print(number_classes)"],"metadata":{"id":"GcD7l4FspuDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Our first visualization!** Let's create a plot that summarizes the number of classes (or labels) we have in our dataset! After you create the `number_classes` dictionary in the above cell, simply run the cell below."],"metadata":{"id":"Iso0G5pBswWI"}},{"cell_type":"code","source":["# Creating the bar chart and adding the correct labels.  The functions used here correspond to each part of the graph\n","plt.bar(number_classes.keys(), number_classes.values(), width = .5);\n","plt.title(\"Number of Images by Class\");\n","plt.xlabel('Class Name');\n","plt.ylabel('# Images');\n","plt.xticks(rotation='vertical')"],"metadata":{"id":"Uhp4k1ANpwNK"},"execution_count":null,"outputs":[]}]}